{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.60.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba)\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\users\\mrun7\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from numba) (2.0.2)\n",
      "Downloading numba-0.60.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.7 MB 487.6 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/2.7 MB 1.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 0.6/2.7 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.7 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/28.1 MB 42.3 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 2.2/28.1 MB 28.4 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 3.1/28.1 MB 27.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.9/28.1 MB 28.6 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.4/28.1 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 7.3/28.1 MB 27.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 8.5/28.1 MB 27.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 10.0/28.1 MB 27.9 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 11.2/28.1 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 12.0/28.1 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 13.0/28.1 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 14.2/28.1 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 15.0/28.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 16.4/28.1 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 17.2/28.1 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 18.2/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 19.1/28.1 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 20.1/28.1 MB 21.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 21.0/28.1 MB 20.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 23.0/28.1 MB 22.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.1/28.1 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.7/28.1 MB 25.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 27.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 22.5 MB/s eta 0:00:00\n",
      "Installing collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.43.0 numba-0.60.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\mrun7\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrun7\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import heapq\n",
    "import pickle\n",
    "import numba as nb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"ops_weights\" : np.array([1.0, 6.0, 3.0]),\n",
    "    \"test_ops_weights\" : np.array([1.0, 6.0, 3.0]),\n",
    "    \"time_weight\":[3,3,3],\n",
    "    \"hours_co_visitation_click\":0.07,\n",
    "    \"hours_co_visitation_buy\":0.06,\n",
    "    \"topn\":20,\n",
    "    \"seq_weight\":[-3,-4,-2], \n",
    "    \"rank_w\":[-4,-4,-5],\n",
    "    \"base_time_weight\":[1.4,1.4,1.4],\n",
    "    \"tail\":100\n",
    "}\n",
    "\n",
    "tail = params[\"tail\"]\n",
    "parallel = 1024\n",
    "\n",
    "\n",
    "OP_WEIGHT = 0; TIME_WEIGHT = 1\n",
    "\n",
    "ops_weights = params[\"ops_weights\"]\n",
    "test_ops_weights = params[\"test_ops_weights\"]\n",
    "topn = params[\"topn\"]\n",
    "\n",
    "\n",
    "\n",
    "time_covisitation=[0,0]\n",
    "time_covisitation[TIME_WEIGHT]=params[\"hours_co_visitation_click\"]\n",
    "time_covisitation[OP_WEIGHT]=params[\"hours_co_visitation_buy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\mrun7\\Downloads\\train.csv\\train.csv\")\n",
    "df_test = pd.read_csv(r\"C:\\Users\\mrun7\\Downloads\\test.csv\\test.csv\")\n",
    "df = pd.concat([df, df_test]).reset_index(drop = True)\n",
    "npz = np.load(r\"C:\\Users\\mrun7\\Downloads\\train.npz\\train.npz\")\n",
    "npz_test = np.load(r\"C:\\Users\\mrun7\\Downloads\\test.npz\\test.npz\")\n",
    "aids = np.concatenate([npz['aids'], npz_test['aids']])\n",
    "ts = np.concatenate([npz['ts'], npz_test['ts']])\n",
    "ops = np.concatenate([npz['ops'], npz_test['ops']])\n",
    "\n",
    "df[\"idx\"] = np.cumsum(df.length) - df.length\n",
    "df[\"end_time\"] = df.start_time + ts[df.idx + df.length - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_test=len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'), dtype('uint8'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids.dtype,ts.dtype,ops.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1517085, 1563459, 1309446]),\n",
       " array([    0,   104, 62639]),\n",
       " array([0, 0, 0], dtype=uint8))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aids[:3],ts[:3],ops[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True, cache = True)\n",
    "def get_single_pairs(pairs, aids, ts, ops, idx, length, start_time, ops_weights, mode,time_weight,hours_co_visitation,base_time_weight):\n",
    "    max_idx = idx + length\n",
    "    min_idx = max(max_idx - tail, idx)\n",
    "    for i in range(min_idx, max_idx):\n",
    "        for j in range(i + 1, max_idx):\n",
    "            if ts[j] - ts[i] >= hours_co_visitation * 60 * 60: break\n",
    "            if aids[i] == aids[j]: continue\n",
    "            if mode == OP_WEIGHT:\n",
    "                w1 = ops_weights[ops[j]]\n",
    "                w2 = ops_weights[ops[i]]\n",
    "            elif mode == TIME_WEIGHT:\n",
    "                w1 = base_time_weight[ops[j]] + time_weight[ops[j]] * (ts[i] + start_time - 1659304800) / (1662328791 - 1659304800)\n",
    "                w2 = base_time_weight[ops[i]] + time_weight[ops[j]] * (ts[j] + start_time - 1659304800) / (1662328791 - 1659304800)\n",
    "            pairs[(aids[i], aids[j])] = w1\n",
    "            pairs[(aids[j], aids[i])] = w2\n",
    "\n",
    "# get pair dict of each session in parallel\n",
    "# merge pairs into a nested dict format (cnt)\n",
    "@nb.jit(nopython = True, parallel = True, cache = True)\n",
    "def get_pairs(aids, ts, ops, row, cnts, ops_weights, mode,time_weight,hours_co_visitation,base_time_weight):\n",
    "    par_n = len(row)\n",
    "    pairs = [{(0, 0): 0.0 for _ in range(0)} for _ in range(par_n)]\n",
    "    for par_i in nb.prange(par_n):\n",
    "        _, idx, length, start_time = row[par_i]\n",
    "        get_single_pairs(pairs[par_i], aids, ts, ops, idx, length, start_time, ops_weights, mode,time_weight,hours_co_visitation,base_time_weight)\n",
    "    for par_i in range(par_n):\n",
    "        for (aid1, aid2), w in pairs[par_i].items():\n",
    "            if aid1 not in cnts: cnts[aid1] = {0: 0.0 for _ in range(0)}\n",
    "            cnt = cnts[aid1]\n",
    "            if aid2 not in cnt: cnt[aid2] = 0.0\n",
    "            cnt[aid2] += w\n",
    "    \n",
    "# util function to get most common keys from a counter dict using min-heap\n",
    "# overwrite == 1 means the later item with equal weight is more important\n",
    "# otherwise, means the former item with equal weight is more important\n",
    "# the result is ordered from higher weight to lower weight\n",
    "@nb.jit(nopython = True, cache = True)\n",
    "def heap_topk(cnt, overwrite, cap):\n",
    "    q = [(0.0, 0, 0) for _ in range(0)]\n",
    "    for i, (k, n) in enumerate(cnt.items()):\n",
    "        if overwrite == 1:\n",
    "            heapq.heappush(q, (n, i, k))\n",
    "        else:\n",
    "            heapq.heappush(q, (n, -i, k))\n",
    "        if len(q) > cap:\n",
    "            heapq.heappop(q)\n",
    "    return [heapq.heappop(q)[2] for _ in range(len(q))][::-1]\n",
    "   \n",
    "# save top-k aid2 for each aid1's cnt\n",
    "@nb.jit(nopython = True, cache = True)\n",
    "def get_topk(cnts, topk, k):\n",
    "    for aid1, cnt in cnts.items():\n",
    "        topk[aid1] = np.array(heap_topk(cnt, 1, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14231/14231 [09:29<00:00, 24.97it/s]\n",
      "100%|██████████| 14231/14231 [08:07<00:00, 29.22it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topks = {}\n",
    "\n",
    "# for two modes\n",
    "for mode in [OP_WEIGHT, TIME_WEIGHT]:\n",
    "    # get nested counter\n",
    "    cnts = nb.typed.Dict.empty(\n",
    "        key_type = nb.types.int64,\n",
    "        value_type = nb.typeof(nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)))\n",
    "    max_idx = len(df)\n",
    "    for idx in tqdm(range(0, max_idx, parallel)):\n",
    "        row = df.iloc[idx:min(idx + parallel, max_idx)][['session', 'idx', 'length', 'start_time']].values\n",
    "        get_pairs(aids, ts, ops, row, cnts, ops_weights, mode,params[\"time_weight\"],time_covisitation[mode],params[\"base_time_weight\"])\n",
    "\n",
    "    # get topk from counter\n",
    "    topk = nb.typed.Dict.empty(\n",
    "            key_type = nb.types.int64,\n",
    "            value_type = nb.types.int64[:])\n",
    "    get_topk(cnts, topk, topn)\n",
    "\n",
    "    del cnts; gc.collect()\n",
    "    topks[mode] = topk\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.jit(nopython = True, cache = True)\n",
    "def inference_(aids, ops, row, result, topk, test_ops_weights, seq_weight, rank_w):\n",
    "    for session, idx, length in row:\n",
    "        rank_weight = np.power(2, np.linspace(rank_w, 0, topn))[::-1]\n",
    "        unique_aids = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "        cnt = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "        cnt_additional_items = nb.typed.Dict.empty(key_type = nb.types.int64, value_type = nb.types.float64)\n",
    "        \n",
    "        candidates = aids[idx:idx + length][::-1]\n",
    "        candidates_ops = ops[idx:idx + length][::-1]\n",
    "        for a in candidates:\n",
    "            unique_aids[a] = 0\n",
    "        sequence_weight = np.power(2, np.linspace(seq_weight, 0, len(candidates)))[::-1]\n",
    "        for a, op, w in zip(candidates, candidates_ops, sequence_weight):\n",
    "            if a not in cnt: \n",
    "                cnt[a] = 0\n",
    "            cnt[a] += w * test_ops_weights[op]\n",
    "            \n",
    "        if len(unique_aids) >= 20:\n",
    "            result_candidates = heap_topk(cnt, 0, 20)\n",
    "        else:\n",
    "            result_candidates = list(unique_aids)\n",
    "            for a,w in zip(cnt,sequence_weight):\n",
    "                if a not in topk: \n",
    "                    continue\n",
    "                for rank, b in enumerate(topk[a]):\n",
    "                    if b in unique_aids: \n",
    "                        continue\n",
    "                    if b not in cnt_additional_items: \n",
    "                        cnt_additional_items[b] = 0\n",
    "                    cnt_additional_items[b] += w*rank_weight[rank] # add weight equal to the frequency of the weight of the corresponding item\n",
    "            result_candidates.extend(heap_topk(cnt_additional_items, 0, 20 - len(result_candidates)))\n",
    "        result[session] = np.array(result_candidates)\n",
    "        \n",
    "\n",
    "@nb.jit(nopython = True)\n",
    "def inference(aids, ops, row, \n",
    "              result_clicks, result_buy,result_order,\n",
    "              topk_clicks, topk_buy,\n",
    "              test_ops_weights,seq_weight,rank_w):\n",
    "    inference_(aids, ops, row, result_clicks, topk_clicks, test_ops_weights, seq_weight[0],rank_w[0])\n",
    "    inference_(aids, ops, row, result_buy, topk_buy, test_ops_weights, seq_weight[1],rank_w[1])\n",
    "    inference_(aids, ops, row, result_order, topk_buy, test_ops_weights, seq_weight[2],rank_w[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1633/1633 [01:41<00:00, 16.05it/s]\n"
     ]
    }
   ],
   "source": [
    "result_clicks = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "result_buy = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "result_order = nb.typed.Dict.empty(\n",
    "    key_type = nb.types.int64,\n",
    "    value_type = nb.types.int64[:])\n",
    "for idx in tqdm(range(len(df) - len_test, len(df), parallel)):\n",
    "    row = df.iloc[idx:min(idx + parallel, len(df))][['session', 'idx', 'length']].values\n",
    "    inference(aids, ops, row, result_clicks, result_buy,result_order, topks[TIME_WEIGHT], topks[OP_WEIGHT], test_ops_weights,params[\"seq_weight\"],params[\"rank_w\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899779_clicks</td>\n",
       "      <td>59625 737445 731692 1790770 1660529 1253524 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899780_clicks</td>\n",
       "      <td>1142000 736515 973453 582732 487136 1502122 88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899781_clicks</td>\n",
       "      <td>918667 199008 194067 57315 141736 759436 16815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899782_clicks</td>\n",
       "      <td>834354 595994 740494 987399 889671 779477 1007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899783_clicks</td>\n",
       "      <td>1817895 607638 1754419 1216820 1729553 300127 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      session_type                                             labels\n",
       "0  12899779_clicks  59625 737445 731692 1790770 1660529 1253524 19...\n",
       "1  12899780_clicks  1142000 736515 973453 582732 487136 1502122 88...\n",
       "2  12899781_clicks  918667 199008 194067 57315 141736 759436 16815...\n",
       "3  12899782_clicks  834354 595994 740494 987399 889671 779477 1007...\n",
       "4  12899783_clicks  1817895 607638 1754419 1216820 1729553 300127 ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs = []\n",
    "op_names = [\"clicks\", \"carts\", \"orders\"]\n",
    "for result, op in zip([result_clicks, result_buy, result_order], op_names):\n",
    "\n",
    "    sub = pd.DataFrame({\"session_type\": result.keys(), \"labels\": result.values()})\n",
    "    sub.session_type = sub.session_type.astype(str) + f\"_{op}\"\n",
    "    sub.labels = sub.labels.apply(lambda x: \" \".join(x.astype(str)))\n",
    "    subs.append(sub)\n",
    "    \n",
    "sub = pd.concat(subs).reset_index(drop = True)\n",
    "sub.to_csv(r\"C:\\Users\\mrun7\\Downloads\\submission.csv\", index = False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
